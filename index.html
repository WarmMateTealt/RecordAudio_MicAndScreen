<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width">
  <title>replit</title>
  <link href="style.css" rel="stylesheet" type="text/css" />
</head>

<body>
  <p>
    This example shows you the contents of the selected part of your display.
    Click the Start Capture button to begin.
  </p>

  <p>
    <button id="start">Start Capture</button>&nbsp;<button id="stop">
      Stop Capture
    </button>
  </p>

  <iframe width="560" height="315" src="https://www.youtube.com/embed/Na0w3Mz46GA?si=jEysFGmOO1jFk6or" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

  <strong>Log:</strong>
  <br />
  <pre id="log"></pre>

  <audio id="recording" controls></audio> <!--esse pra ver o áudio-->
  <a id="downloadButton" class="button">Download</a>

  
</body>

</html>

<script>
  const logElem = document.getElementById("log");
  const startElem = document.getElementById("start");
  const stopElem = document.getElementById("stop");
  const recordingElem = document.getElementById("recording");
  var sourceToStop_01;
  var sourceToStop_02;
  var recorderToStop;

  // Options for getDisplayMedia()

  // não tem como capturar só áudio; a esperança é isolar o áudio com ferramentas do kit mesmo
  // loucura de SOMEHOW fazer o browser só sugerir a própria guia :)
  // (https://stackoverflow.com/questions/73742556/how-to-use-navigator-getdisplaymedia-with-auto-selecting-the-screen) e
  // (https://stackoverflow.com/questions/75912092/navigator-mediadevices-getdisplaymedia-does-not-show-the-current-tab)
  const displayMediaOptions = {
    video: {
      displaySurface: "browser",
    },
    audio: {
      channelCount: 2,
      echoCancellation: true,
      noiseSuppression: true,
    },
    selfBrowserSurface: "include",
    monitorTypeSurface: "exclude",
    preferCurrentTab: true,
    
  };

  // Set event listeners for the start and stop buttons
  startElem.addEventListener(
    "click",
    (evt) => {
      startCapture();
    },
    false,
  );

  stopElem.addEventListener(
    "click",
    (evt) => {
      stopCapture();
    },
    false,
  );

  console.log = (msg) => (logElem.textContent = `${logElem.textContent}\n${msg}`);
  console.error = (msg) =>
    (logElem.textContent = `${logElem.textContent}\nError: ${msg}`);

  async function startCapture() {
    logElem.textContent = "";

    try {
      userMicStream = await navigator.mediaDevices.getUserMedia({video: false,audio: true,});
      sourceToStop_01 = userMicStream;
      displayMediaCombinedStream = await navigator.mediaDevices.getDisplayMedia(displayMediaOptions);
      sourceToStop_02 = displayMediaCombinedStream;
      //throw error and call stop rec (release streams) if any of these go awry

      const audioTrackFromCombined = displayMediaCombinedStream.getAudioTracks()[0];
      const videoTrackFromCombined = displayMediaCombinedStream.getVideoTracks()[0];
      videoTrackFromCombined.stop();
      // ^ aqui a esperança é matar o fluxo de vídeo, mantendo o de áudio vivo 
      //(https://github.com/w3c/mediacapture-screen-share-extensions/issues/12#issuecomment-1960941085)

      // multiple audio tracks extraction from stream
      //(https://stackoverflow.com/questions/75598622/how-do-i-capture-only-audio-from-mediadevices-getdisplaymedia)
      // audio stream union
      //(https://stackoverflow.com/questions/64717758/merge-two-audio-tracks-into-one-track)
      var OutgoingMediaStream = new MediaStream();
      for (const track of displayMediaCombinedStream.getAudioTracks()) {
          OutgoingMediaStream.addTrack(track);
      }
      var IngoingMediaStream = new MediaStream(userMicStream);

      const audioContext = new AudioContext();

      audioIn_01 = await audioContext.createMediaStreamSource(OutgoingMediaStream);
      audioIn_02 = await audioContext.createMediaStreamSource(IngoingMediaStream);
      
      mediaStreamDestination = audioContext.createMediaStreamDestination();

      audioIn_01.connect(mediaStreamDestination);
      audioIn_02.connect(mediaStreamDestination);
      
      var finalStream = mediaStreamDestination.stream;

      console.log("started rec\n");
      const recordedChunks = await startRecording(finalStream);
      console.log("stopped rec\n");
      // pra parar ainda to usando o hack do video mas como audio :D

      let recordedBlob = new Blob(recordedChunks, { type: "audio/webm" });
      recording.src = URL.createObjectURL(recordedBlob);
      downloadButton.href = recording.src;
      downloadButton.download = "RecordedAudio.webm";

      log(
        `Successfully recorded ${recordedBlob.size} bytes of ${recordedBlob.type} media.`,
      );
      
      dumpOptionsInfo();
    } catch (err) {
      stopCapture();
      console.error(err);
    }
  }

  function stopCapture(evt) {
    console.log('stop function fired\n');
    
    let tracks = sourceToStop_01.getTracks();
    tracks.forEach((track) => track.stop());
    
    tracks = sourceToStop_02.getTracks();
    tracks.forEach((track) => track.stop());

    recorderToStop.stop();
  }

  function dumpOptionsInfo() {
    const audioTracks = recordingElem.srcObject.getAudioTracks();

    for (const track of audioTracks) {
      console.log("Audio Track " + track.id + ":\n");
      console.log("Track settings:\n");
      console.log(JSON.stringify(track.getSettings(), null, 2));
      console.log("Track constraints:\n");
      console.log(JSON.stringify(track.getConstraints(), null, 2));
      console.log('\n');
    }
    
  }


  // pegar a stream de mic do usuário;
  //    nota: tanto redirecionar pro mix, quanto enviar ela pro destino normal;
  // pegar a stream que captura o áudio da tela do user
  //    mesmo esquema da stream de microfone
  // juntar os dois em uma stream sendo salva

  // função de gravar original; ela para no stop, ou após lengthInMS 
  function startRecordingTimed(stream, lengthInMS) {
    let recorder = new MediaRecorder(stream);
    let data = [];

    recorder.ondataavailable = (event) => data.push(event.data);
    recorder.start();
    log(`${recorder.state} for ${lengthInMS / 1000} seconds…`);

    let stopped = new Promise((resolve, reject) => {
      recorder.onstop = resolve;
      recorder.onerror = (event) => reject(event.name);
    });

    let recorded = wait(lengthInMS).then(() => {
      if (recorder.state === "recording") {
        recorder.stop();
      }
    });

    return Promise.all([stopped, recorded]).then(() => data);
  }

  // função de gravar alterada: só para de gravar no evento de stop do recorder (espera-se)
  function startRecording(stream) {
    recorderToStop = new MediaRecorder(stream);
    let data = [];

    recorderToStop.ondataavailable = (event) => data.push(event.data);
    recorderToStop.start();
    log(`${recorderToStop.state} - audio channel`);

    let stopped = new Promise((resolve, reject) => {
      recorderToStop.onstop = resolve;
      recorderToStop.onerror = (event) => reject(event.name);
    });

    return stopped.then(() => data);
  }

  function log(msg) {
    logElem.innerText += `${msg}\n`;
  }

  function wait(delayInMS) {
    return new Promise((resolve) => setTimeout(resolve, delayInMS));
  }
  
</script>